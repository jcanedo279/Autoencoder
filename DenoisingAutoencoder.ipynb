{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import wandb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import random \n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "wandb.login()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjorgecanedo\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class DenoisingAutoencoder:\n",
    "    def __init__(self, config, dataset, dataset_path, loss_function, optim_function):\n",
    "        self.config = config\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.loss_fn = loss_function\n",
    "        self.optim_fn = optim_function\n",
    "\n",
    "        self.model_pipeline(dataset_path)\n",
    "        \n",
    "        \n",
    "    def model_pipeline(self, dataset_path):\n",
    "        with wandb.init(project='DAE', config=self.config):\n",
    "            self.config = wandb.config\n",
    "            \n",
    "            self.make(dataset_path)\n",
    "            \n",
    "            ### Model Training ###\n",
    "            self.train_model()\n",
    "            self.plot_model_loss()\n",
    "            \n",
    "            ### Model Testing ###\n",
    "            self.test_model().item()\n",
    "            \n",
    "            self.save_model()\n",
    "            \n",
    "        \n",
    "    def make(self, dataset_path):\n",
    "        ## Make Data\n",
    "        self.load_dataset(dataset_path)\n",
    "        self.visualizer()\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        ## Make Model\n",
    "        self.encoder = self.Encoder(encoded_space_dim=self.config.latent_dim)\n",
    "        self.decoder = self.Decoder(encoded_space_dim=self.config.latent_dim)\n",
    "        \n",
    "        ## Make Optimizer\n",
    "        self.params_to_optimize = [ {'params': self.encoder.parameters()}, {'params': self.decoder.parameters()} ]\n",
    "        self.optim = self.optim_fn(self.params_to_optimize, lr=self.config.learning_rate, weight_decay=self.config.weight_decay)\n",
    "        \n",
    "        ## Move Model\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        print(f'Selected device: {self.device}')\n",
    "        self.encoder.to(self.device)\n",
    "        self.decoder.to(self.device)\n",
    "            \n",
    "    def save_model(self):\n",
    "        torch.onnx.export(self.encoder, self.trian_dataset, 'encoder.onnx', export_params=True)\n",
    "        print('Model has been converted to ONNX')\n",
    "            \n",
    "             \n",
    "    #######################\n",
    "    ## Encoder Sub Class ##\n",
    "    #######################\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self, encoded_space_dim):\n",
    "            super().__init__()\n",
    "            self.encoder_cnn = nn.Sequential(\n",
    "                nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "            ## Linear Layers\n",
    "            self.flatten = nn.Flatten(start_dim=1)\n",
    "            self.encoder_lin = nn.Sequential(\n",
    "                nn.Linear(3 * 3 * 32, 128),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(128, encoded_space_dim)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.encoder_cnn(x)\n",
    "            x = self.flatten(x)\n",
    "            x = self.encoder_lin(x)\n",
    "            return x\n",
    "    \n",
    "    #######################\n",
    "    ## Decoder Sub Class ##\n",
    "    #######################\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self, encoded_space_dim):\n",
    "            super().__init__()\n",
    "            self.decoder_lin = nn.Sequential(\n",
    "                nn.Linear(encoded_space_dim, 128),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(128, 3 * 3 * 32),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "            ## Linear Layers\n",
    "            self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "            self.decoder_conv = nn.Sequential(\n",
    "                nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.decoder_lin(x)\n",
    "            x = self.unflatten(x)\n",
    "            x = self.decoder_conv(x)\n",
    "            x = torch.sigmoid(x)\n",
    "            return x\n",
    "    \n",
    "    #####################\n",
    "    ## Dataset Methods ##\n",
    "    #####################\n",
    "    def load_dataset(self, dataset_path):\n",
    "        ## Initialize datasets\n",
    "        train_dataset = self.dataset(dataset_path, train=True, download=True)\n",
    "        test_dataset  = self.dataset(dataset_path, train=False, download=True)\n",
    "        ## Define transformers\n",
    "        train_transform = transforms.Compose( [transforms.ToTensor(),] )\n",
    "        test_transform = transforms.Compose( [transforms.ToTensor(),] )\n",
    "        ## Define transformed datasets\n",
    "        train_dataset.transform = train_transform\n",
    "        test_dataset.transform = test_transform\n",
    "        ## Define train test split\n",
    "        num_train = len(train_dataset)\n",
    "        num_test = num_train*train_test_split\n",
    "        ## Split training data\n",
    "        train_data, val_data = random_split(train_dataset, [int(num_train-num_test), int(num_test)])\n",
    "        ## Define data loaders\n",
    "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=self.config.batch_size)\n",
    "        valid_loader = torch.utils.data.DataLoader(val_data, batch_size=self.config.batch_size)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "        ## Return\n",
    "        self.train_dataset, self.test_dataset = train_dataset, test_dataset\n",
    "        self.train_loader, self.valid_loader, self.test_loader = train_loader, valid_loader, test_loader\n",
    "\n",
    "    def visualizer(self):\n",
    "        data = self.train_loader.dataset[0]\n",
    "        tensor = data[0]\n",
    "        plt.imshow(tensor.numpy()[0], cmap='gray')\n",
    "        plt.title('Sample Image From Training Dataset')\n",
    "\n",
    "    def add_noise(self, data):\n",
    "        new_data = copy.deepcopy(data)\n",
    "        for tensor_ind, tensor in enumerate(new_data):\n",
    "            rand_tensor = noise_factor * torch.rand(tensor.shape)\n",
    "            new_tensor = tensor.add(rand_tensor)\n",
    "            new_data[tensor_ind] = new_tensor / torch.max(new_tensor)\n",
    "        return new_data\n",
    "\n",
    "    #############################\n",
    "    ## Iterative Model Methods ##\n",
    "    #############################\n",
    "    def train_model(self):\n",
    "        wandb.watch(self.encoder, log=\"all\", log_freq=10)\n",
    "        wandb.watch(self.decoder, log=\"all\", log_freq=10)\n",
    "        \n",
    "        model_loss = {'train_loss':[], 'test_loss':[]}\n",
    "        \n",
    "        num_batches = 0\n",
    "        for epoch in tqdm(range(self.config.epochs)):\n",
    "            train_loss = self.train_batch()\n",
    "            test_loss = self.test_model()\n",
    "            model_loss['train_loss'].append(train_loss)\n",
    "            model_loss['test_loss'].append(test_loss)\n",
    "            \n",
    "            num_batches += self.config.batch_size\n",
    "            \n",
    "            self.train_log(train_loss, test_loss, epoch, num_batches)\n",
    "            print(f'EPOCH {epoch + 1}/{self.config.epochs} \\t train loss {train_loss} \\t test loss {test_loss}')\n",
    "            self.plot_sample_batch()\n",
    "\n",
    "        self.model_loss = model_loss\n",
    "    \n",
    "    def train_batch(self):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for image_batch, _ in self.train_loader:\n",
    "            noisy_batch = self.add_noise(image_batch)\n",
    "            noisy_batch = noisy_batch.to(self.device)    \n",
    "            \n",
    "            encoded_batch = self.encoder(noisy_batch)\n",
    "            decoded_batch = self.decoder(encoded_batch)\n",
    "            \n",
    "            conc_out, conc_label = decoded_batch.cpu(), image_batch.cpu()\n",
    "            \n",
    "            loss_mse = self.loss_fn(decoded_batch, image_batch)\n",
    "            loss_cat = self.loss_fn(conc_out, conc_label)\n",
    "            loss = loss_mse + loss_cat\n",
    "            \n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "            train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        return np.mean(train_loss)\n",
    "    \n",
    "    def train_log(self, train_loss, test_loss, epoch, step):\n",
    "        train_loss, test_loss = float(train_loss), float(test_loss)\n",
    "        wandb.log({'train_loss': train_loss, 'test_loss': test_loss, 'epoch': epoch, 'step': step})\n",
    "        \n",
    "    def test_model(self):\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            conc_out = []\n",
    "            conc_label = []\n",
    "\n",
    "            for image_batch, _ in self.test_loader:\n",
    "                noisy_batch = self.add_noise(image_batch)\n",
    "                noisy_batch = noisy_batch.to(self.device)\n",
    "\n",
    "                encoded_batch = self.encoder(noisy_batch)\n",
    "                decoded_batch = self.decoder(encoded_batch)\n",
    "\n",
    "                conc_out.append(decoded_batch.cpu())\n",
    "                conc_label.append(image_batch.cpu())\n",
    "\n",
    "            conc_out = torch.cat(conc_out)\n",
    "            conc_label = torch.cat(conc_label) \n",
    "            val_loss = self.loss_fn(conc_out, conc_label)\n",
    "            \n",
    "        return val_loss.data\n",
    "\n",
    "    ######################\n",
    "    ## Plotting Methods ##\n",
    "    ######################\n",
    "    def plot_model_loss(self):\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.semilogy(self.model_loss['train_loss'], label='Train')\n",
    "        plt.semilogy(self.model_loss['test_loss'], label='Test')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Batch Average Loss')\n",
    "        plt.title('Model Loss Per Epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_sample_batch(self):\n",
    "        n = num_display_images\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        \n",
    "        for i in range(n):\n",
    "            img = self.test_dataset[i][0].unsqueeze(0).to(self.device)\n",
    "            noisy_img = self.add_noise(img)\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            with torch.no_grad():\n",
    "                rec_img  = self.decoder(self.encoder(noisy_img))\n",
    "            \n",
    "            ax = plt.subplot(3, n, i+1)\n",
    "            plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)  \n",
    "            if i == math.floor(n/2):\n",
    "                ax.set_title('Source Images')\n",
    "\n",
    "            ax = plt.subplot(3, n, i+1+n)\n",
    "            plt.imshow(noisy_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)  \n",
    "            if i == math.floor(n/2):\n",
    "                ax.set_title('Input Images (Noisy)')\n",
    "\n",
    "            ax = plt.subplot(3, n, i+1+ 2*n)\n",
    "            plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)  \n",
    "            if i == math.floor(n/2):\n",
    "                ax.set_title('Reconstructed Images')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_latent_images(self, r0=(-10, 10), r1=(-10, 10), width=28, space_definition=20):\n",
    "        plt.figure(figsize=(20, 8.5))\n",
    "        img = np.zeros((space_definition*width, space_definition*width))\n",
    "        for i, y in enumerate(np.linspace(*r1, space_definition)):\n",
    "            for j, x in enumerate(np.linspace(*r0, space_definition)):\n",
    "                z = torch.Tensor([[x, y]]).to(self.device)\n",
    "                x_hat = self.decoder(z).reshape(width, width).to('cpu').detach().numpy()\n",
    "                img[(space_definition-1-i)*width:(space_definition-1-i+1)*width, j*width:(j+1)*width] = x_hat\n",
    "        plt.imshow(img, extent=[*r0, *r1], cmap='gist_gray')\n",
    "        plt.title('Decoded Visualization of Latent Space')\n",
    "\n",
    "    ##########################\n",
    "    ## Latent Space Methods ##\n",
    "    ##########################\n",
    "    def gen_latent_pop(self, samp_size=0):\n",
    "        ## samp_size = 0 samples the entire test population\n",
    "        latent_pop = []\n",
    "        for samp_ind, sample in enumerate(tqdm(self.test_dataset)):\n",
    "            if samp_size != 0 and samp_ind > samp_size:\n",
    "                break\n",
    "            img = sample[0].unsqueeze(0).to(self.device)\n",
    "            label = sample[1]\n",
    "            \n",
    "            self.encoder.eval()\n",
    "            with torch.no_grad():\n",
    "                latent_val  = self.encoder(img)\n",
    "            \n",
    "            latent_val = latent_val.flatten().cpu().numpy()\n",
    "            latent_samp = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(latent_val)}\n",
    "            latent_samp['label'] = label\n",
    "            latent_pop.append(latent_samp)\n",
    "        latent_pop_df = pd.DataFrame(latent_pop)\n",
    "        latent_pop_df.head()\n",
    "        return latent_pop_df\n",
    "\n",
    "    def plot_latent_topology(self, latent_pop_df):\n",
    "        ### Euclidean Graph ###\n",
    "        #######################\n",
    "        fig = px.scatter(\n",
    "            latent_pop_df, x='Enc. Variable 0', y='Enc. Variable 1',\n",
    "            color=latent_pop_df.label.astype(str), opacity=0.7,\n",
    "        )\n",
    "        fig.update_layout(title='2D Representation of Datapoints in Latent Space')\n",
    "        fig.show()\n",
    "        ### TSNE Graph ###\n",
    "        ##################\n",
    "        tsne = TSNE(n_components=2)\n",
    "        tsne_results = tsne.fit_transform(latent_pop_df.drop(['label'], axis=1))\n",
    "        fig = px.scatter(\n",
    "            tsne_results, x=0, y=1,\n",
    "            color=latent_pop_df.label.astype(str), labels={'0':'tsne-2d-0', '1':'tsne-2d-1'}\n",
    "        )\n",
    "        fig.update_layout(title='TSNE Representation of Datapoints in Latent Space')\n",
    "        fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Autoencoder Parameters\n",
    "latent_dim = 2\n",
    "\n",
    "# Autoencoder Learning Parameters\n",
    "lr = 0.001\n",
    "weight_decay = 1e-3\n",
    "train_test_split = 0.2\n",
    "\n",
    "loss_fn = MSELoss()\n",
    "optim_fn = Adam\n",
    "\n",
    "# (training) number of epochs spent training\n",
    "num_epochs = 10\n",
    "\n",
    "# (training + testing) batch size\n",
    "batch_size = int(256/2)\n",
    "\n",
    "# (training + testing) image noise level\n",
    "noise_factor = 1\n",
    "\n",
    "num_display_images = 9\n",
    "\n",
    "latent_samp_size = 0\n",
    "\n",
    "dataset_path = 'data'\n",
    "dataset = FashionMNIST"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'params'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/m2b90dwj1yb4_vx37kp75lq40000gn/T/ipykernel_11269/3202272938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moptim_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# (training) number of epochs spent training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config = {\n",
    "    'latent_dim': latent_dim,\n",
    "    'noise_factor': noise_factor,\n",
    "    'epochs': num_epochs,\n",
    "    'classes': 10,\n",
    "    'batch_size': batch_size,\n",
    "    'weight_decay': weight_decay,\n",
    "    'train_test_split': train_test_split,\n",
    "    'learning_rate': lr,\n",
    "    'loss_function': 'MSE',\n",
    "    'dataset': 'FashionMNIST',\n",
    "    'architecture': 'Autoencoder'\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ae = DenoisingAutoencoder(config, dataset, dataset_path, loss_fn, optim_fn)\n",
    "\n",
    "\n",
    "ae.plot_latent_images(r0=(-1, 1), r1=(-1, 1))\n",
    "latent_pop_df = ae.gen_latent_pop(samp_size=latent_samp_size)\n",
    "ae.plot_latent_topology(latent_pop_df)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}